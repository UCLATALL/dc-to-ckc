## 8.7 Correlation

You might have heard of *Pearson’s r,* often referred to as a "correlation coefficient." Correlation is just a special case of regression in which both the outcome and explanatory variables are transformed into z scores prior to analysis.  

<iframe data-type="learnosity" id="Ch8_Correlation_1"  src="https://coursekata.org/learnosity/preview/Ch8_Correlation_1" width="100%" height="420"></iframe>

Let’s see what happens when we transform the two variables we have been working with: **Thumb** length and **Height**. Because both variables are transformed into z scores, the mean of each distribution will be 0, and the standard deviation will be 1. The function ```zscore()``` will convert all the values in a variable to z scores. 

<p><iframe data-type="datacamp" id="ch8-8" style="border: 0px #ffffff none;" src="https://uclatall.github.io/czi-stats-course/data-camp/chapter-8/ch8-8" width="100%" height="350" ></iframe></p>

Let’s make a scatter plot of **zThumb** and **zHeight** and look at the distribution. Then also make (again) a scatter plot of **Thumb** and **Height**, and compare the two scatter plots. 

<iframe data-type="learnosity" id="Ch8_Correlation_2"  src="https://coursekata.org/learnosity/preview/Ch8_Correlation_2" width="100%" height="760"></iframe>

Make two scatter plots by modifying the code below. 

<p><iframe data-type="datacamp" id="ch8-9" style="border: 0px #ffffff none;" src="https://uclatall.github.io/czi-stats-course/data-camp/chapter-8/ch8-9" width="100%" height="350" ></iframe></p> 

<p align="center" style="text-align: center;"><img src="https://i.postimg.cc/BvygPG1c/Xc9cf91.png" width=100% alt="A scatterplot of the distribution of Thumb by Height in Fingers on the left. A scatterplot of the distribution of zThumb by zHeight in Fingers on the right. The two distributions look the same except the scale of the axes." /></p> 

<iframe data-type="learnosity" id="Ch8_Correlation_3"  src="https://coursekata.org/learnosity/preview/Ch8_Correlation_3" width="100%" height="1270"></iframe>

### Fitting the Regression Model to the Two Distributions

In the code window below we’ve provided the code to fit a regression line for ```Thumb``` based on ```Height```. Below that code, fit a regression model to the two transformed variables, using ```zThumb``` as the outcome variable (instead of ```Thumb```) and ```zHeight``` as the explanatory variable (instead of ```Height```). Save the model in an R object called ```zHeight.model```. 

Then, print the model estimates for both the ```zHeight.model``` and the ```Height.model```. 

<p><iframe data-type="datacamp" id="ch8-10" style="border: 0px #ffffff none;" src="https://uclatall.github.io/czi-stats-course/data-camp/chapter-8/ch8-10" width="100%" height="350" ></iframe></p>

Next, redo the two scatter plots, this time overlaying the best-fitting regression line for each one. 

<p><iframe data-type="datacamp" id="ch8-11" style="border: 0px #ffffff none;" src="https://uclatall.github.io/czi-stats-course/data-camp/chapter-8/ch8-11" width="100%" height="350" ></iframe></p>

Below we’ve organized the results of all this in a table: the two scatter plots, best-fitting regression lines, and estimated model parameters. 

<p align="center" style="text-align: center;"><img src="https://i.postimg.cc/4d91zF6C/wcw47sT.png" width=100% alt="A scatterplot of the distribution of Thumb by Height in Fingers overlaid with the regression line on the left. According to the output of the lm function, the coefficients are -3.3295 for Intercept and 0.9619 for Height. A scatterplot of the distribution of zThumb by zHeight in Fingers overlaid with the regression line on the right. According to the output of the lm function, the coefficients are -1.801e-16 for Intercept and 3.911e-1 for Height." /></p> 

<iframe data-type="learnosity" id="Ch8_Correlation_4"  src="https://coursekata.org/learnosity/preview/Ch8_Correlation_4" width="100%" height="300"></iframe>

Note that R will sometimes express parameter estimates in scientific notation. Thus, -1.801e-16 means that the decimal point is shifted 16 digits to the left. So, the actual y-intercept of the best-fitting regression line is -.00000000000000018. Which is, for all practical purposes, 0.

We know from earlier that the best-fitting regression line passes through the mean of both the outcome and explanatory variables. Note that in the case of ```zThumb``` and ```zHeight```, the middle of the scatter plot is at 0 on both the x- and y-axes. The y-intercept is 0 in this model because when x is 0, y is also 0. 

<iframe data-type="learnosity" id="Ch8_Correlation_5"  src="https://coursekata.org/learnosity/preview/Ch8_Correlation_5" width="100%" height="1430"></iframe>

### Comparing the Fit of the Two Models

Let’s now run ```supernova()``` on the two models, and compare their fit to the data. 

<p><iframe data-type="datacamp" id="ch8-12" style="border: 0px #ffffff none;" src="https://uclatall.github.io/czi-stats-course/data-camp/chapter-8/ch8-12" width="100%" height="350" ></iframe></p> 

<pre><code>Analysis of Variance Table
Outcome variable: Thumb
Model: lm(formula = Thumb ~ Height, data = Fingers)
 
                               SS  df       MS      F    PRE     p
 ----- ----------------- -------- --- -------- ------ ------ -----
 Model (error reduced) |   1816.9   1 1816.862 27.984 0.1529 .0000
 Error (from model)    |  10063.3 155   64.925                    
 ----- ----------------- -------- --- -------- ------ ------ -----
 Total (empty model)   |  11880.2 156   76.155
</pre></code>

<pre><code>Analysis of Variance Table
Outcome variable: zThumb
Model: lm(formula = zThumb ~ zHeight, data = Fingers)
 
                               SS  df      MS      F    PRE     p
 ----- ----------------- -------- --- ------- ------ ------ -----
 Model (error reduced) |   23.857   1 23.8574 27.984 0.1529 .0000
 Error (from model)    |  132.143 155  0.8525                    
 ----- ----------------- -------- --- ------- ------ ------ -----
 Total (empty model)   |  156.000 156  1.0000
</pre></code>

<iframe data-type="learnosity" id="Ch8_Correlation_6"  src="https://coursekata.org/learnosity/preview/Ch8_Correlation_6" width="100%" height="440"></iframe>

**The fit of the models is identical because all we have changed is the unit in which we measure the outcome and explanatory variables.** We saw when we first introduced z scores that transforming an entire distribution into z scores did not change the shape of the distribution, but only the mean and standard deviation (to 0 and 1).

The same thing is true when we transform both the outcome and explanatory variables. The z transformation does not change the shape of the bivariate distribution, as represented in the scatter plot, at all. It simply changes the scale on both axes to standard deviations instead of inches and millimeters.

Unlike PRE, which is a proportion of the total, SS are expressed in the units of the measurement. So if we converted the mm (for ```Thumb``` length) and inches (for ```Height```) into cm, feet, etc, the SS would change to reflect those new units. 
